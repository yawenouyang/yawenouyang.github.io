<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Yawen Ouyang&#39;s Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Yawen Ouyang">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Yawen Ouyang">
<meta property="og:description" content="Yawen Ouyang&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yawen Ouyang">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Yawen Ouyang</title>
  








<meta name="generator" content="Hexo 5.4.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yawen Ouyang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/06/25/Energy-based-Unknown-Intent-Detection-with-Data-Manipulation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/25/Energy-based-Unknown-Intent-Detection-with-Data-Manipulation/" itemprop="url">Energy-based Unknown Intent Detection with Data Manipulation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-25T21:25:33+08:00">
                2021-06-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Review-Report"><a href="#Review-Report" class="headerlink" title="Review Report"></a>Review Report</h3><h4 id="MetaReview"><a href="#MetaReview" class="headerlink" title="MetaReview"></a>MetaReview</h4><p>This paper extents a previous work of energy scores to detect OOD utterances in open dialogue systems. All reviewers agree that the proposed approach is an interesting idea. Main concerns are about experimental comparisons. The authors addressed most “reason to reject” comments of the reviewers. However, reviewer 2’ comments on the weakness are not fully addressed. Especially, the comments on variety and coherency of augmentation.</p>
<h4 id="Overall-Recommendation"><a href="#Overall-Recommendation" class="headerlink" title="Overall Recommendation"></a>Overall Recommendation</h4><p>Review #1: 3.5/5; Review #2: 3/5; Review #3: 3.5/5</p>
<h3 id="Postscript-by-Yawen"><a href="#Postscript-by-Yawen" class="headerlink" title="Postscript (by Yawen)"></a>Postscript (by Yawen)</h3><p>Admittedly, I’m not that satisfied with this paper. </p>
<p>There are some claims in the paper that I didn’t explain carefully, such as why OOD utterances akin to IND utterances could be more effective in shaping the energy gap. </p>
<p>There are also some typos:</p>
<ul>
<li>In section 3.2, “the energy function $-E(\mathbf{u})$” is wrong, the correct version is “the negative energy function $-E(\mathbf{u})$”.</li>
<li>In section 3.2, the parentheses of exponential function in Equation 3 and 4 should be “()”, not “[]”.</li>
<li>In the implementation paragraph in Section 4.1, “$E_y$” should be “$\mathbf{E}_y$”.</li>
<li>In Table 1, “validation” should be “Validation”.</li>
</ul>
<p>I am very sorry if they have confused you in your reading.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/06/25/Dialogue-State-Tracking-with-Explicit-Slot-Connection-Modeling/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/06/25/Dialogue-State-Tracking-with-Explicit-Slot-Connection-Modeling/" itemprop="url">Dialogue State Tracking with Explicit Slot Connection Modeling</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-06-25T21:21:34+08:00">
                2021-06-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Review-Report"><a href="#Review-Report" class="headerlink" title="Review Report"></a>Review Report</h3><h4 id="MetaReview"><a href="#MetaReview" class="headerlink" title="MetaReview"></a>MetaReview</h4><p>This paper proposes a DST model that leverages the related slots from different domains. A slot connecting mechanism is proposed to build connections across domains. All reviewers agreed that the model is simple, technically sound, and effective. Some questions raised by reviewers are addressed by authors, and R1 is inclined to increase the score to 4. Hence, all reviewers agreed to accept this paper and the suggested decision is “accept”.</p>
<h4 id="Overall-Recommendation"><a href="#Overall-Recommendation" class="headerlink" title="Overall Recommendation"></a>Overall Recommendation</h4><p>Review #1: 4/5; Review #2: 3.5/5; Review #3: 4.5/5</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/05/PCA-and-SVD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/05/05/PCA-and-SVD/" itemprop="url">PCA and SVD</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-05T14:48:04+08:00">
                2020-05-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>主要记录PCA与SVD的关系</p>
<h2 id="PCA-principle-component-analysis"><a href="#PCA-principle-component-analysis" class="headerlink" title="PCA(principle component analysis)"></a>PCA(principle component analysis)</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>正交属性空间的样本点，如何找到一个合适的超平面对所有样本进行恰当的表达。</p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>PCA: 希望找到一组正交基$\mathbf{P}$，使得样本$\mathbf{X} \in \mathbf{R}^{n \times m}$变化后各维度之间可以互相独立，这里$m$是样本个数，$n$是特征个数。</p>
<h2 id="做法"><a href="#做法" class="headerlink" title="做法"></a>做法</h2><p>变化后的样本：$\mathbf{Y} = \mathbf{PX}$</p>
<p>如果各维度互相独立，则$\mathbf{Y}$的协方差$\mathbf{S}_Y$则为对角矩阵(这里假设$\mathbf{X}$已经中心化后了)：</p>
<script type="math/tex; mode=display">\mathbf{S}_Y = \frac{1}{m-1}\mathbf{Y}\mathbf{Y}^T=\frac{1}{m-1}\mathbf{PX}\mathbf{X}^T\mathbf{P}^T</script><p>这里$\frac{1}{m-1}\mathbf{XX}^T$是$\mathbf{X}$的协方差，其特征值分解为：$\mathbf{EDE}^T$，$\mathbf{E}$是特征向量，$\mathbf{D}$是特征值，是对角矩阵，代入上式可得：</p>
<script type="math/tex; mode=display">\mathbf{S}_Y = \mathbf{PEDE}^T\mathbf{P}^T</script><p>这里$\frac{1}{m-1}\mathbf{XX}^T$是对称矩阵，其特征向量$\mathbf{E}$是正交矩阵，即$\mathbf{EE}^T = \mathbf{I}$，此时这要取$\mathbf{P=E}^T$，代入上式可得：</p>
<script type="math/tex; mode=display">\mathbf{S}_Y = \mathbf{E}^T\mathbf{EDE}^T\mathbf{E} = \mathbf{D}</script><p>满足对角阵，所以样本$\mathbf{X}$的协方差的特征向量即可满足要求。</p>
<h2 id="SVD-singular-value-decomposition"><a href="#SVD-singular-value-decomposition" class="headerlink" title="SVD(singular value decomposition)"></a>SVD(singular value decomposition)</h2><p>对于任意一个矩阵$\mathbf{A} \in \mathbf{R}^{m \times n}$，都可以分解为$\mathbf{U \Sigma V}^T$，其中$\mathbf{U}$，$\mathbf{V}$是正交阵，$\mathbf{\Sigma}$是对角阵，称为它的奇异值。</p>
<p>很容易证明的是$\mathbf{U}$是$\mathbf{AA}^T$的特征向量，$\mathbf{V}$是$\mathbf{A}^T\mathbf{A}$的特征向量，$\mathbf{\Sigma}$是$\mathbf{A}^T\mathbf{A}$特征值的平方根。</p>
<p>如果取$\mathbf{A} = \frac{\mathbf{X}^T}{\sqrt{m-1}}$，那么$\mathbf{A}^T\mathbf{A} = \frac{1}{m-1}\mathbf{XX}^T$，所以PCA问题可以转化为SVD问题求解：$\mathbf{X}$转化为$\mathbf{A}$后，通过求解其他方式来对$\mathbf{A}$进行奇异值分解，得到的$\mathbf{V}^T$即为解。</p>
<p>测试代码：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line"></span><br><span class="line">X = np.array([[9, -2, -3, 1, 2], [8, -1, -2, 1, 1]])  # 特征 * 样本</span><br><span class="line">pca = PCA(n_components=2)</span><br><span class="line">pca.fit(np.transpose(X))  # PCA要求的输入是 样本 * 特征</span><br><span class="line">print(&#x27;特征向量: &#123;&#125;&#x27;.format(pca.components_))</span><br><span class="line">print(&#x27;特征值: &#123;&#125;&#x27;.format(pca.explained_variance_))</span><br><span class="line"></span><br><span class="line">X = X - np.mean(X, axis=1).reshape(2, -1)  # 中心化</span><br><span class="line">X = np.transpose(X) / np.sqrt(X.shape[1] - 1)</span><br><span class="line">U,sigma,VT = np.linalg.svd(X)</span><br><span class="line">print(&#x27;VT: &#123;&#125;&#x27;.format(VT))</span><br><span class="line">print(&#x27;奇异值: &#123;&#125;&#x27;.format(sigma))</span><br><span class="line">print(&#x27;奇异值的平方: &#123;&#125;&#x27;.format(np.power(sigma, 2)))</span><br></pre></td></tr></table></figure></p>
<p>输出:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">特征向量: [[ 0.77066593  0.63723938]</span><br><span class="line"> [ 0.63723938 -0.77066593]]</span><br><span class="line">特征值: [37.43169343  0.16830657]</span><br><span class="line">VT: [[-0.77066593 -0.63723938]</span><br><span class="line"> [ 0.63723938 -0.77066593]]</span><br><span class="line">奇异值: [6.11814461 0.41025184]</span><br><span class="line">奇异值的平方: [37.43169343  0.16830657]</span><br></pre></td></tr></table></figure>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><ol>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/58064462">https://zhuanlan.zhihu.com/p/58064462</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/38319536/answer/131029607">https://www.zhihu.com/question/38319536/answer/131029607</a></p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/24/optimizer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/04/24/optimizer/" itemprop="url">optimizer</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-24T21:02:27+08:00">
                2020-04-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文记录了一些常见的优化器，只有大概，很多地方理解还不到位。</p>
<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p>梯度下降(Gradient Descent)包括三类：批量梯度下降(full-batch gradient descent, 有时也称为batch gradient descent)，随机梯度下降(stochastic gradient descent)，小批量梯度下降(mini-batch gradient descent)。</p>
<p>以目标函数$J(\theta) = \sum^m_{i=1} J(\theta;x^{(i)}, y^{(i)})$为例，其中$m$为样本个数</p>
<h3 id="full-batch-GD"><a href="#full-batch-GD" class="headerlink" title="full-batch GD"></a>full-batch GD</h3><p>每次更新权重需要用到所有的样本，也就是直接用$J(\theta)$对$\theta$求偏导。更新公式：</p>
<script type="math/tex; mode=display">
    \theta = \theta - \eta\nabla_\theta J(\theta)</script><p>优点：由于直接优化的是目标函数$J(x)$，所以对于凸优化问题，肯定能达到最优解，对于非凸，肯定能到达极值点。在样本量不大时，收敛也很快。</p>
<p>缺点：样本很多时，更新一次要很久，样本需要实时加入(on-the-fly)时，也不能用。</p>
<h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p>每次更新只用到了一个样本，更新公式：</p>
<script type="math/tex; mode=display">
    \theta = \theta - \eta\nabla_\theta J(\theta;x^{(i)}, y^{(i)})</script><p>优点：对于$m$个样本中相同或相似的样本，梯度也相似，full-batch则进行了冗余的计算，SGD直觉上会更省时。理论上也可以证明，[1]证明了在样本数量足够多时，SGD的计算复杂度更低(达到误差小于$\epsilon$的目标，需要求梯度的次数)：SGD：$O(\frac{1}{\epsilon})$，full-batch GD：$O(nlog(\frac{1}{\epsilon}))$。</p>
<p>缺点：SGD的波动性很强，因此可能会跳出极值点，但收敛会更难一些。</p>
<h3 id="mini-batch-GD"><a href="#mini-batch-GD" class="headerlink" title="mini-batch GD"></a>mini-batch GD</h3><p>用部分样本$n$近似全部，更新公式：</p>
<script type="math/tex; mode=display">
    \theta = \theta - \eta\nabla_\theta J(\theta; x^{i:i+n}, y^{i:i+n})</script><p>综合了GD和SGD的特点，更稳定收敛的同时，又能够更高效的计算(目前深度学习库可以更好地并行)。</p>
<p>$\textbf{以上缺点}:$ 所有参数都使用的是相同的学习率，对于稀疏的特征，我们学习率想更大一些，梯度下降往往做不到。</p>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p>Momentum通过累计梯度的方式来加快训练速度，或是跳出极值点：</p>
<script type="math/tex; mode=display">
v_t = \gamma v_{t-1} + \eta\nabla_\theta J(\theta) \\
\theta = \theta - v_t</script><p>不同参数的学习率仍相同。</p>
<h2 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h2><p>使历史的梯度影响参数的学习率，达到历史梯度越大的参数的学习率越小，历史梯度越小的参数的学习率越大，对于$\theta<em>i$，$t$时刻的$J(\theta)$对其的偏导记为$g</em>{t,i}$:</p>
<script type="math/tex; mode=display">
n_{t,i} = n_{t,i} + g_{t,i}^2 \\
\theta_{t,i} = \theta_{t,i} - \frac{\eta}{\sqrt{n_{t,i}} +  \epsilon} g_{t,i}</script><p>其中$\alpha$是新的学习率，$\eta$是全局学习率，$\epsilon$是防止分母为0</p>
<p>特点：学习率跟梯度相关：在较平缓的地方会获得更大的学习率，在较陡峭的地方会降低学习率。但由于$n_t$是递增，这会导致学习率最后会非常低。</p>
<h2 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h2><p>修改了$n_t$的计算：</p>
<script type="math/tex; mode=display">
n_{t,i} = \gamma n_{t,i} + (1-\gamma)g_{t,i}^2</script><p>这里其实$n<em>{t,i}$想表示的是$g</em>{t,i}^2$的期望，RMSProp亦是如此，两者几乎同时提出。</p>
<p>主要优点：RMSprop和Adadelta在non-stationary(非平稳)设置下会更适合，所谓非平稳是指优化函数会发生变化(可能更适合多任务学习？)，这里还不能太理解原因。</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>Momentum和RMSProp的结合：</p>
<script type="math/tex; mode=display">
v_{t,i} = \beta_1 v_{t-1,i} + (1-\beta_1)g_{t,i} \\
n_{t,i} = \beta_2 n_{t,i} + (1-\beta_2)g_{t,i}^2</script><p>Adam又指出这里$v<em>{t,i}，n</em>{t,i}$并不能代表$g<em>{t,i}，g</em>{t,i}^2$的期望，作者进行了校准：</p>
<script type="math/tex; mode=display">
\hat{v_{t,i}} = \frac{v_{t,i}}{1-\beta_1^t}
\\
\hat{n_{t,i}} = \frac{n_{t,i}}{1-\beta_2^t}</script><p>最后进行参数更新：</p>
<script type="math/tex; mode=display">
\theta_{t,i} = \theta_{t,i} - \frac{\eta}{\sqrt{\hat{n_{t,i}}} +  \epsilon} \hat{v_{t,i}}</script><p>论文中的参考文献指出RMSprop+动量也有相关工作，Adam与它们的不同是使用动量的方式不同，Adam另外还进行了bias操作。</p>
<p>主要优点：结合了Adagrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点。</p>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><p>[1] Optimization Methods for Large-Scale Machine Learning<br>[2] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28060786">https://zhuanlan.zhihu.com/p/28060786</a><br>[3] <a target="_blank" rel="noopener" href="https://ruder.io/optimizing-gradient-descent/">https://ruder.io/optimizing-gradient-descent/</a><br>[4] ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/02/Zero-Shot-Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/02/Zero-Shot-Learning/" itemprop="url">Zero-Shot Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-02T16:12:31+08:00">
                2018-11-02
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Zero-Shot-Learning"><a href="#Zero-Shot-Learning" class="headerlink" title="Zero-Shot Learning"></a>Zero-Shot Learning</h1><h2 id="0-前言"><a href="#0-前言" class="headerlink" title="0 前言"></a>0 前言</h2><p>这周主要看了Zero-Shot Learning(以下简称ZSL)的一些文章，看ZSL是为了解决Intent Classification中的New Intent(Unseen)的问题，即只知道Intent Label但没有关于这个类别的训练数据。</p>
<h2 id="1-基础知识"><a href="#1-基础知识" class="headerlink" title="1 基础知识"></a>1 基础知识</h2><h3 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h3><p>有关ZSL的解释都大同小异，这里选取(可能)最早出现ZSL的paper中对其的定义”where the possible values for the class variable Y include values that have been omitted from the training examples”[1]</p>
<h3 id="1-2-Semantic-Space"><a href="#1-2-Semantic-Space" class="headerlink" title="1.2 Semantic Space"></a>1.2 Semantic Space</h3><p>ZSL在CV上备受关注，主要原因是图像类别较多，标注困难，这里就先介绍在CV上的相关工作。</p>
<p>总体来看，目前CV上要解决ZSL问题，都会引入Semantic Space作为外部信息，主要有三种类型的Semantic:</p>
<ol>
<li>Attribute space. 即每个类别的属性，属性可以有多种，比如对于一个动物来说，是否哺乳，是否有尾巴等等，那为每个类别标注属性就又变得很困难。</li>
<li>Word vector. 直接用类别的word vector作为Semantic信息，好处是容易获得，但是信息有限。</li>
<li>Textual description. 对类别的描述，好处也是容易获得(可以来自维基百科等)，信息较多，但信息中可能含有Noise.</li>
</ol>
<p>有了Semantic的信息后，可以利用已知的类别学Visual Space和Semantic Space之间的映射，其中Visual Space是图片本身的特征，可用预训练好的网络来提取，维度较高，有了映射关系后，来了新样本可以先对它提取Visual feature，然后映射到Semantic space，得到Semantic feature后与所有类别的Semantic feature做KNN，即可得到所属类别。</p>
<h2 id="2-主要问题"><a href="#2-主要问题" class="headerlink" title="2 主要问题"></a>2 主要问题</h2><p>以下主要参考了[3]</p>
<h3 id="2-1-领域漂移问题（domain-shift-problem）"><a href="#2-1-领域漂移问题（domain-shift-problem）" class="headerlink" title="2.1 领域漂移问题（domain shift problem）"></a>2.1 领域漂移问题（domain shift problem）</h3><p>描述：同一属性(Attribute)，在不同domain的里表现出的Visual feature差异巨大，比如”有尾巴”这一属性，狐狸的尾巴和猪的尾巴就相差甚远，如果用狐狸的图片来训练Visual到Semantic的映射关系，那模型见到猪的图片时就可能会在是否有尾巴这一Semantic Feature上判断为否，进而预测错误。</p>
<p>解决(缓解)方法：由于Visual Space的维度大于Semantic Space，所以由Visual到Semantic的映射会丢失信息，如果保留的信息越多，就能够保留更多的丰富性，就可能缓解这一问题，[4]中利用AutoEncoder的思想，采取的做法是将由Visual映射得到Semantic信息，在重新映射回去得到Visual信息，从而强迫Semantic保留更多的信息，以此来缓解这一问题。</p>
<p><strong>回到我们的问题，Intent Label Space和Sentence Space本身都是由词表示的，空间映射这一步骤上应该会好很多，目前意图识别应用在聊天客服等任务型对话中居多，那这个聊天通常也是在同一领域内的，所以也不会有domain shift的问题，那新意图检测这个任务有没有想象中那么难，可能要重新评估一下了。</strong></p>
<h3 id="2-2-枢纽点问题（hubness-problem）"><a href="#2-2-枢纽点问题（hubness-problem）" class="headerlink" title="2.2 枢纽点问题（hubness problem）"></a>2.2 枢纽点问题（hubness problem）</h3><p>描述：高维空间中，某些点会成为大多数点的最近邻点[4]。ZSL最终在计算时通常是使用KNN，所以会受该问题的影响。</p>
<p>解决(缓解)方法：由于Visual Space的维度大于Semantic Space，所以映射到Semantic Space后，点与点之间更加稠密，从而加重hubness problem，反向思维一下，就把Semantic Space映射到Visual Space中即可减缓这一问题。</p>
<h2 id="3-相关工作-持续更新"><a href="#3-相关工作-持续更新" class="headerlink" title="3 相关工作(持续更新)"></a>3 相关工作(持续更新)</h2><h3 id="3-1-缓解domain-shift-problem"><a href="#3-1-缓解domain-shift-problem" class="headerlink" title="3.1 缓解domain shift problem"></a>3.1 缓解domain shift problem</h3><p>代表论文：Semantic AutoEncoder for Zero-Shot Learning(CVPR 2017)</p>
<p>本文主要缓解domain shift problem，其实这种方法只能通过AE的方法，使得映射到的特征保留更多信息来缓解这一问题，并不能解决。</p>
<h3 id="3-2-借助Knowledge-Gragh"><a href="#3-2-借助Knowledge-Gragh" class="headerlink" title="3.2 借助Knowledge Gragh"></a>3.2 借助Knowledge Gragh</h3><p>上面提到Semantic Space可以是label的WordVector，而仅仅只考虑单个label的Vector信息而忽略label correlation，而correlation信息可以通过KG来表示。</p>
<p>代表论文：</p>
<p>Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs（CVPR 2018）</p>
<p>这里类别之间的KG通过归一化的二进制邻接矩阵$\hat{A} \in{n \times n}$来表示，n是类别数量，Graph Convolutional Network(GCN)表示为：$Z=\hat{A}X’W$，这里$X’ \in {n \times k}$是上一层的输入，最初是类别的embedding，$W \in {k \times c}$是权重矩阵，是要学习的，c是output channels，本层得到的输出$output \in {n \times c}$加个激活函数可以输入下一层。最终得到输出层是$\hat{W} \in {n \times D}$，D是分类器的参数的维度。</p>
<p>先利用已知类别的数据去训练已知类别的分类器的，训练好后，用这些参数作为监督信息去训练GCN，最终得到未知类别的参数。</p>
<p>Multi-Label Zero-Shot Learning with Structured Knowledge Graphs(CVPR 2018)</p>
<p>本文中更详细的定义了label之间的关系，包括：super-subordinate(下属，通过WordNet直接得到)，positive(正相关，通过WUP[5]计算)，negative(负相关，通过WUP计算)，每种关系都对应一个函数$a_{vu}=F^k_R(w_v,w_u)$来得到两个label之间的propagation weights.关系函数和在已知类别上的分布可以通过训练集得到，测试的时候通过已知类别与未知类别的关系来得到在位未知类别上的分布。</p>
<h3 id="3-3-生成样本"><a href="#3-3-生成样本" class="headerlink" title="3.3 生成样本"></a>3.3 生成样本</h3><p>ZSL就是没有Unseen Class的样本，随着GAN，VAE技术的兴起和成熟，大家开始用这些技术来为这些Class生成样本。</p>
<p>代表工作：</p>
<p>A Generative Adversarial Approach for Zero-Shot Learning from Noisy Texts(CVPR 2018)</p>
<p>这篇主要是使用GAN来通过类别描述(来自Wikipedia)生成样本。</p>
<p>训练过程是生成器来给文本+ $z\sim N(0,1)$建模得到semantic feature，判别器是判断输入的特征是来自文本还是图片(图片的特征可由事先训好的网络提取)，同时判别器也判断该特征是属于哪一个类别，最终要达到的目的是生成器可以通过新类别的文本来生成plausible image feature。</p>
<p>训练时还有一个trick：通过对已知类别的visual feature降维观察，发现已知visual feature已经有较高的类内相似性和较低的类间相似性，所以想让生成的semantic feature也保证同样的特性，所以引入了Pivot Regularization，先计算每个已知类别在visual feature上的平均值作为pivot，然后使得生成的semantic feature使其与自身类别在visual space的pivot更相似。</p>
<p>GAN训练好后，就可以为Unseen Class的生成不同semantic feature(class description + gaussian sampled $z$)，最后计算平均值得到pivot，测试样本来了之后与各个类别的pivot做KNN即可预测类别。</p>
<p>A Generative Model For Zero Shot Learning Using Conditional Variational Autoencoders(CVPR 2018)也是同一时间段的工作，也用了类似的思想，不过是使用了Conditional VAE代替了GAN。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>主要参考[3]</p>
<p>(1) <a target="_blank" rel="noopener" href="https://cvml.ist.ac.at/AwA/">Animal with Attributes</a></p>
<p>(2) <a target="_blank" rel="noopener" href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html">Caltech-UCSD-Birds-200-2011（CUB）</a></p>
<p>(3) <a target="_blank" rel="noopener" href="http://groups.csail.mit.edu/vision/SUN/">Sun database（SUN）</a></p>
<p>(4) <a target="_blank" rel="noopener" href="http://vision.cs.uiuc.edu/attributes/">Attribute Pascal and Yahoo dataset（aPY)</a></p>
<p>(5) ILSVRC2012/ILSVRC2010（ImNet-2）</p>
<p>Train和Test的类别分布有两种：</p>
<ol>
<li>Train Class和Test Class不存在交集，即测试集中存在的都是新类别，这是一个非常强的假设，真实世界中不会存在，但能够很好地判定seen class泛化到unseen class的性能。</li>
<li>Test Class中同样包含Train Class，比较符合真实的规律。</li>
</ol>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p>类别之间的样本数量不均衡时：<br>$acc^{per-class}<em>{avg}=\frac{1}{Y}\sum^{|Y|}</em>{i=0}\frac{N^{class-i}{correct}}{N^{class-i}{total}}$</p>
<p>均衡时：$acc^{per-image}<em>{avg}=\frac{N</em>{correct}}{N_{total}}$</p>
<p>对于ImageNet这种类别比较多的，可采用Top K的方式，即前K个最邻近的包括正确的标签即可。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>[1] Zero-Shot Learning with Semantic Output Codes</p>
<p>[2] Hubness and Pollution: Delving into Class-Space Mapping for Zero-Shot Learning.</p>
<p>[3] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34656727">https://zhuanlan.zhihu.com/p/34656727</a></p>
<p>[4] Hubness and Pollution: Delving into Class-Space Mapping for Zero-Shot Learning.</p>
<p>[5] Verbs semantics and lexical selection.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/16/cnn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/16/cnn/" itemprop="url">cnn</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-16T10:46:39+08:00">
                2018-07-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文是阅读魏秀参发布的<a target="_blank" rel="noopener" href="http://lamda.nju.edu.cn/weixs/book/CNN_book.html">CNN</a>的记录与思考。</p>
<h1 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h1><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>机器学习：人工智能的一个分支，致力于如何通过计算的手段，利用经验(experience)改善计算系统自身的性能，这里经验往往对应以特征(feature)的形式存储的数据(data)，传统机器学习算法便是通过这些数据产生模型。</p>
<p>机器学习摒弃了人为向机器输入知识的操作，转而凭借算法自身来学所需的知识。</p>
<p>特征的好坏决定了性能的好坏，人们通过特征工程(feature engineering)形式的工程试错性的方式来得到数据特征。人们也尝试将特征学习这一过程也用机器自动”学”出来，这便是”表示学习”(representation learning),”深度学习”便是表示学习的一个经典代表。</p>
<p>深度学习以数据的原始形态(raw data)，经过算法层层抽象，将原始数据抽象为自身任务所需的最终特征表示，最后以特征到任务目标的映射作为结束。</p>
<p>深度学习除了模型学习，还有特征学习、特征抽象等任务模块的参与，借助多层任务模块完成最终学习任务，故称作”深度”学习。</p>
<p><img src="/2018/07/16/cnn/dl.png" alt="关系图"></p>
<p>深度学习的伟大之处在于，真正让研究者或工程师摆脱了复杂的特征工程，从而可以专注于解决更加宏观的关键问题。</p>
<h1 id="卷积神经网络基本部件"><a href="#卷积神经网络基本部件" class="headerlink" title="卷积神经网络基本部件"></a>卷积神经网络基本部件</h1><p>过去解决一个人工智能问题，往往通过分治法将其分解为预处理、特征提取与选择、分类器设计等若干步骤，分布解决子问题时，尽管在子问题上得到最优解，但在子问题上的最优并不意味着就能得到全局问题的最后解。</p>
<p>“端到端”即从元输入到期望输出的映射完全交给模型，有更大可能获得全局最优解。</p>
<h2 id="符号表示"><a href="#符号表示" class="headerlink" title="符号表示"></a>符号表示</h2><p>用三维张量$x^l \in R^{H^l \times W^l \times D^l}$表示卷积神经网络第l蹭的输入，用三元组$(i^l,j^l,d^l)$来指示该张量对应第$i^l$行,第$j^l$列,第$d^l$通道(channel)位置的元素。</p>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>三维输入时卷及操作实际只是将二维卷积扩展到了对应位置的所有通道上(即$D^l$)，最终将以此卷积处理的所有$HWD^l$个元素求和作为该卷积位置结果。</p>
<h2 id="卷积核的作用"><a href="#卷积核的作用" class="headerlink" title="卷积核的作用"></a>卷积核的作用</h2><p>卷积核作用于局部图像区域获得图像的局部信息。</p>
<p>以下为三种边缘卷积核(亦可称为滤波器)：<br><img src="/2018/07/16/cnn/边缘卷积核.png" alt="滤波器"></p>
<p>$K^e$可检测整体边缘滤波器，若某像素(x,y)处在物体边缘，即四周的像素点与(x,y)会有显著差异，即$k^e$不为0，即检测出边缘。若不在边缘，四周的与像素点与(x,y)应该差不多，此时$k^e$为0。类似$k^h$和$k^v$的横向、纵向边缘滤波器可分别保留横向、纵向的边缘信息。</p>
<p>这些卷积核都是网络学出来的，可以学到任意角度的边缘滤波器，还有检测颜色、形状、纹理等等。</p>
<h2 id="汇合"><a href="#汇合" class="headerlink" title="汇合"></a>汇合</h2><p>汇合包括平均汇合和最大汇合。</p>
<p>不需要参数，仅需要核大小(kernel size)和步长(stride)等超参数。</p>
<p>每一层都有一个汇合核，第$l$层的汇合核可表示为$p^l \in R^(H \times W \times D^l)$</p>
<p>汇合层作用：</p>
<ol>
<li>特征不变形。汇合操作使模型更关注是否存在某些特征而不是特征的具体位置。</li>
<li>特征降维，减小了下一层输入大小，进而减小计算量和参数个数。</li>
</ol>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>激活函数的引入为的是增强网络的表达能力(即非线性)。</p>
<h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>如果说卷积层、汇合层和激活函数层等操作是将原始数据映射到隐层特征 空间的话，全连接层则起到将学到的特征表示映射到样本的标记空间的作用。</p>
<h1 id="卷积神经网络经典结构"><a href="#卷积神经网络经典结构" class="headerlink" title="卷积神经网络经典结构"></a>卷积神经网络经典结构</h1><h2 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h2><p><img src="/2018/07/16/cnn/感受野.png" alt="感受野"><br>由图可知，小卷积核可通过多层叠加取得与大卷积核同等规模的感受野。</p>
<p>小卷积核的好处：</p>
<ol>
<li>加深了网络深度进而增强了网络容量和复杂度。</li>
<li>增强网络容量的同时减少了参数的个数。假设卷积核对应的输入输出特征张量的深度均为C，则$7\times7$的卷积核对应参数有$C\times(7\times7\times C)=49C^2$个，$3\times3$卷积核仅需要$3\times C\times(3\times3\times C)=27C^2$个。</li>
</ol>
<h2 id="分布式表示"><a href="#分布式表示" class="headerlink" title="分布式表示"></a>分布式表示</h2><p>通过实验证明，对于某个模式，如鸟的躯干，会有不同的卷积核(其实就是神经元)产生响应，对于某个卷积核，会在不同模式上产生响应，如躯干和头部。</p>
<p>除了分布式表示特性，神经网络响应多呈现”稀疏”(sparse)特性，即响应区域集中占原图比例较小。</p>
<h2 id="深度特征的层次性"><a href="#深度特征的层次性" class="headerlink" title="深度特征的层次性"></a>深度特征的层次性</h2><p>卷积操作可获取图像区域不同类型特征，汇合等操作是对特征进行融合和抽象。</p>
<p>随着卷积核汇合等操作的堆叠，各层得到的深度特征逐渐从泛化特征(边缘、纹理)过度到高层语义表示(躯干、头部)。</p>
<h2 id="经典网络之Alex-Net"><a href="#经典网络之Alex-Net" class="headerlink" title="经典网络之Alex-Net"></a>经典网络之Alex-Net</h2><p>Alex-Net于2012年ImageNet竞赛中取得冠军。</p>
<p>模型：<img src="/2018/07/16/cnn/alexnet.png" alt="alexnet"></p>
<p>在网络结构和基本操作方面，Alex-Net改进很小，仅在网络深度和复杂度上游较大优势。</p>
<p>其他贡献：</p>
<ol>
<li>首先将cnn用于cv领域。</li>
<li>利用gpu进行网络训练。</li>
<li>提出了一些trick，比如使用relu，dropout(随机失活)，还有局部响应规范化(LRN)，要求对相同空间位置上相邻深度的卷积结果做规范化。</li>
</ol>
<h2 id="经典网络之残差网络模型"><a href="#经典网络之残差网络模型" class="headerlink" title="经典网络之残差网络模型"></a>经典网络之残差网络模型</h2><p>公式可表示为: $y=F(x,w)+x$，做简单变换后，可得: $F(x,w)=y-x$，残差项为$y-x$，称为残差函数。</p>
<p>模型：<img src="/2018/07/16/cnn/残差网络.png" alt="残差网络"></p>
<p>通过这种近路连接的方式，即使面对特别深的网络，也可以通过反向传播端到端学习。</p>
<p>残差网络以全局平均汇合从代替了全连接层，一方面使得参数减少，一方面减少了过拟合的风险。</p>
<h1 id="卷积神经网络的压缩"><a href="#卷积神经网络的压缩" class="headerlink" title="卷积神经网络的压缩"></a>卷积神经网络的压缩</h1><p>神经网络面临严峻的过参数化(over-parameterization)。</p>
<p>总体而言，绝大多数的压缩算法，均是将庞大而复杂的预训练模型(pre-trained model)转为一个精简的小模型。</p>
<p>压缩技术分为”前端压缩”和”后端压缩”。</p>
<p>前端压缩：不改变原网络结构的压缩技术。主要包括知识蒸馏、紧凑的模型结构设计、滤波器层面的剪枝。</p>
<p>后端压缩：尽可能减少模型的大小，不得不对原有的网络结构进行改造，这样的改造往往不可逆。主要包括低秩近似、未加限制的剪枝、参数量化以及二值网络等。</p>
<h2 id="低秩近似"><a href="#低秩近似" class="headerlink" title="低秩近似"></a>低秩近似</h2><p>对卷积过程所需要的权重矩阵(通常稠密且巨大)进行重构，具体方法包括结构化矩阵，使用局矩阵分解来降低权重矩阵的参数。</p>
<p>低秩近似适用于中小型网络，主要是由于其超参数量与网络层数呈线性变化趋势，随着网络层数的增加与模型复杂度的提升，搜索空间会急剧增大。</p>
<h2 id="剪枝与稀疏约束"><a href="#剪枝与稀疏约束" class="headerlink" title="剪枝与稀疏约束"></a>剪枝与稀疏约束</h2><p>剪枝的好处在于能够减小模型的复杂度，还能防止过拟合。</p>
<p>常用的剪枝流程如下：衡量神经元(粒度不同，可以是个权重连接，也可以是整个滤波器)的重要程度，移掉不重要的神经元，对网络进行微调，然后进行下一轮的剪枝。</p>
<p>直接剪权重连接不足之处是剪枝后的网络是非结构化的，需要运行专门的库来运行模型，严重制约了通用性。</p>
<p>剪滤波器的做法之一是根据滤波器权重的绝对值作为其权值，不足是很多情况下，小权值的滤波器对损失函数也能起到重要的影响。</p>
<p>剪滤波器还有一种方案是由数据驱动剪枝，根据网络输出的通道的稀疏程度来判断滤波器的作用，如果一个滤波器输出几乎全部为0，则该滤波器是多余的。但该方法仍是启发式算法， 只能根据实验结果来评价其好坏。</p>
<p>利用稀疏约束对网络进行剪枝也是一个重要的方向(该部分暂时还不是太明白)。</p>
<p>连接级别的剪枝太细，滤波器级别的剪枝太粗。有人提出了结构化系数训练的方法以滤波器、通道、网络深度作为约束对象，将其加到损失函数的约束项中。</p>
<p>剪枝的关键点是如何衡量个别权重对整体模型的重要程度，尤其是对于深度学习而言，几乎不可能从理论上确保某一选择策略是最优的。另一方面，由于剪枝操作对网络结构的破坏程度极小，这种良好的特性往往被当做网络压缩过程的前端处理。将剪枝与其他后端压缩技术相结合，能够达到网络模型的最大程度压缩。</p>
<h2 id="参数量化"><a href="#参数量化" class="headerlink" title="参数量化"></a>参数量化</h2><p>最简单的一种量化算法便是标量量化(scalar quantization)，将权重矩阵转化为向量$w \in R^{1 \times mn}$，然后对权重向量的元素进行k个簇的聚类，记录与码本(codebook)之中，原权重矩阵只负责记录各自聚类中心在码本中的索引。</p>
<h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><p>迁移学习的一种，目的是将一个庞大而复杂的模型所学到的知识，通过一定手段迁移到精简的小模型上，使小模型能够获得和大模型相似的性能。</p>
<p>这里主要包括两个问题，如何提取知识，如何完成迁移。</p>
<p>Jimmy等人认为，softmax层的输入与类别标签相比，包含了更丰富的监督信息，所以他们在实验中选择浅层的小模型来”模仿”深层的大模型，但仍需要很多参数。</p>
<p>Hinton等人认为Softmax层会是更好的选择，可被认为一种”软标签”即不仅包括类别概率，而且还包含了不同类别之间的相似信息，为了更好的获得”软标签”，又引入了温度$T$这一变量来控制平滑程度。该做法不足之处在于，$T$不确定，维度较高时，模型难以收敛。</p>
<p>Luo等人认为Softmax的前一层的输出包含更多的信息，这是因为softmax以此为基础进行计算，但同样包含很多噪声和无关信息，他们设计了一个算法来对这些神经元进行选择，主要思想是，保留那些满足如下两点要求的特征维度:一是该维度的特征须具有足够 强的区分度，二是不同维度之间的相关性须尽可能低。</p>
<p>知识蒸馏目前的效果相对主流的剪枝、量化等技术相比，仍存在一定的差距。</p>
<p>知识蒸馏的主要思想是，小模型相比于大模型可以获得更多的监督信息，大模型只是使用标签数据，小模型可以使用标签数据和大模型的输出，进而获得更好的训练效果。</p>
<h1 id="实践应用"><a href="#实践应用" class="headerlink" title="实践应用"></a>实践应用</h1><h2 id="数据扩充"><a href="#数据扩充" class="headerlink" title="数据扩充"></a>数据扩充</h2><ol>
<li>简单的扩充方式：对图像水平翻转，随机抠取，尺度变换，旋转。</li>
<li>Fancy PCA：对图片的RGB像素值做PCA，得到特征向量和特征值，然后根据这些计算一个扰动值，加入到原像素值中。</li>
<li>监督式数据扩充：首先根据原数据训练一个分类的初始模型，利用该模型生成对应的特征图(可知识图像区域与场景标记间的相关概率)，然后扣取相关概率较大的区域扩充数据。</li>
</ol>
<p>这里思考NLP领域为什么关于数据扩充的方式那么少，这个<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39312449/article/details/80523518">博客</a>我觉得说的很有道理。</p>
<h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>这里说一下交叉熵的来源</p>
<p>说交叉熵之前先看看信息量，信息量必须满足两个条件：</p>
<ol>
<li>越小概率的事件产生的信息量越大=&gt; 与概率负相关</li>
<li>两个独立事件同时发生所带来的信息量是独立发生打来信息量的和=&gt;有对数</li>
</ol>
<p>信息量是对一个具体事件发生所带来的信息，熵是在结果出来之前对所有可能产生的信息量的期望。</p>
<p>即$H(X)=-\sum^n_{i=1}p(x_i)logp(x_i)$</p>
<p>相对熵(KL散度)，来衡量两个分布的差异<script type="math/tex">D_{KL}(p||q) = \sum^n_{i=1}p(x_i)log(p(x_i)/q(x_i))$，$D_KL</script>越小，表示q分布和p分布越接近。</p>
<p>衡量label与predicts之间的差距，使用KL散度距离刚好由于KL散度<script type="math/tex">D_{KL}(p||q) = \sum^n_{i=1}p(x_i)log(p(x_i))) - \sum^n_{i=1}p(x_i)log(q(x_i))</script>，前一部分是常量，只需关注后一部分即交叉熵即可。</p>
<h2 id="网络正则化"><a href="#网络正则化" class="headerlink" title="网络正则化"></a>网络正则化</h2><p>防止过拟合，提升泛化能力。</p>
<ol>
<li>$l_1$，$l_2$。$l_2$正则化效果好于$l_1$，$l_1$可求得稀疏解，二者可联合使用，此时被称为”Elastic”网络正则化。</li>
<li>最大范数约束是通过参数量级的范数设置上限进而进行正则化，可防止”梯度爆炸”。</li>
<li>dropout(随机失活)。加了dropout之后相当于训练阶段训练了几个子网络，测试相当于子网络的平均集成。</li>
<li>验证集。验证集准确率一直低于训练集上的准确率，但无明显下降趋势。这说明此时模型复杂度欠缺，模型表示能力有限——属“欠拟合”状态。若验证集曲线不仅低于训练集，且随着训练轮 数增长有明显下降趋势，说明模型已经过拟合。</li>
<li>加入额外的训练数据。</li>
</ol>
<h2 id="超参数设定和网络训练"><a href="#超参数设定和网络训练" class="headerlink" title="超参数设定和网络训练"></a>超参数设定和网络训练</h2><h2 id="批规范化操作"><a href="#批规范化操作" class="headerlink" title="批规范化操作"></a>批规范化操作</h2><p>Google提出的批规范化操作(batch normalization，简称BN)，可以缓解梯度消失的问题。算法如图所示：<br><img src="/2018/07/16/cnn/bn.png" alt="BN"></p>
<p>前三步操作中规中矩，使得x的均值为0，方差为1，有趣的在第四步，尺度变化和偏移，加这一步的目的是：BN可以看做是原模型上的新操作，这个新操作也就会改变x(当然也有可能不改变)，最后一布的目的是可以还原原始的输入(模型自主的去学$\beta$和$\gamma$)，如此一来网络的容量(capacity)便会提升。</p>
<p>统计机器学习中的一个经典假设是”源空间”和”目标空间”的数据分布式一致的，BN的作用就是规范化输入(固定每层的输入信号的均值和方差)。</p>
<p>以下的图片(来自:<a target="_blank" rel="noopener" href="https://v.youku.com/v_show/id_XMTg1MTYwNDg2OA==">莫烦的视频</a>)对BN解决梯度消失问题做了很直观的说明：<br><img src="/2018/07/16/cnn/bn2.png" alt="BN对梯度消失问题的解决">]</p>
<p>BN一般用在非线性映射函数前，若神经网络训练时收敛速度较慢，或”梯度爆炸”等无法训练的状况发生时也可以尝试用BN解决(解决梯度爆炸怎么说…)。</p>
<h2 id="网络模型优化算法选择"><a href="#网络模型优化算法选择" class="headerlink" title="网络模型优化算法选择"></a>网络模型优化算法选择</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/13/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yawen Ouyang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/06/13/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-06-13T19:49:43+08:00">
                2018-06-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/deployment.html">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yawenouyang" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yawen Ouyang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
